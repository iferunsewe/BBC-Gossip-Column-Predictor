{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3d1e0a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from thefuzz import fuzz, process\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5407ee",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def extract_player_name(row):\n",
    "    return row[\"player_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1b9450",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def extract_clubs_mentioned(row):\n",
    "    return string_to_list(row[\"clubs_mentioned\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ff98f4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Converts a string to a list\n",
    "def string_to_list(my_string):\n",
    "    try:\n",
    "        my_list = eval(my_string)\n",
    "    except:\n",
    "        my_list = my_string.split(\", \")\n",
    "    return my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7813768d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Finds the best match between player names and a list of names using fuzzy string matching\n",
    "def get_best_match(player_name, names_list):\n",
    "    return process.extractOne(player_name, names_list, scorer=fuzz.token_sort_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e4cc33",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def is_player_found(best_match, threshold=50):\n",
    "    return best_match[1] >= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80047417",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Gets the player row from transfermarkt_data based on the best match.\n",
    "def get_player_row(player_name, transfermarkt_data):\n",
    "    best_match = get_best_match(player_name, transfermarkt_data[\"player_name\"])\n",
    "    if is_player_found(best_match):\n",
    "        return transfermarkt_data[transfermarkt_data[\"player_name\"] == best_match[0]]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b820438c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def merge_clubs_left_joined(player_row):\n",
    "    return pd.concat([player_row[\"club_left\"], player_row[\"club_joined\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b595dd8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Checks if all clubs mentioned in the transfer news exist in the clubs left and joined by the player\n",
    "def check_clubs_exist(clubs_mentioned, clubs_left_joined, threshold=75):\n",
    "    clubs_mentioned_set = set(clubs_mentioned)\n",
    "    clubs_found = set()\n",
    "\n",
    "    for mentioned_club in clubs_mentioned_set:\n",
    "        for club in clubs_left_joined.values:\n",
    "            similarity = fuzz.ratio(mentioned_club.lower(), club.lower())\n",
    "            if similarity >= threshold:\n",
    "                clubs_found.add(mentioned_club)\n",
    "                break\n",
    "    \n",
    "    return len(clubs_found) == len(clubs_mentioned_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e002e72",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Determines the veracity of a transfer rumor based on the player found and the clubs mentioned\n",
    "def get_veracity(player_found, player_row, clubs_mentioned):\n",
    "    if player_found:\n",
    "        clubs_left_joined = merge_clubs_left_joined(player_row)\n",
    "        clubs_exist = check_clubs_exist(clubs_mentioned, clubs_left_joined)\n",
    "        return clubs_exist\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0a65c7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def create_output_csv(preprocessed_data):\n",
    "    preprocessed_data.to_csv(utils.get_data_file_path(\"output_data.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c1cfd7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Removes unnecessary columns and rows with missing values\n",
    "def clean_data(data):\n",
    "    columns_to_exclude = [\"raw_text\", \"player_name\", \"date\", \"id\", \"clubs_mentioned\"]\n",
    "    data = data.drop(columns=columns_to_exclude)\n",
    "    data = data.dropna(subset=['veracity'])\n",
    "    data['veracity'] = data['veracity'].astype(int)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa634bd",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Wrangles the data by adding a veracity column to the preprocessed data\n",
    "def wrangle_data(preprocessed_data, verified_data):\n",
    "    veracity_list = []\n",
    "\n",
    "    for i in range(len(preprocessed_data)):\n",
    "        row = preprocessed_data.iloc[i]\n",
    "        player_name = extract_player_name(row)\n",
    "        print(f\"Processing player {player_name}...\")\n",
    "        clubs_mentioned = extract_clubs_mentioned(row)\n",
    "\n",
    "        player_row = get_player_row(player_name, verified_data)\n",
    "        player_found = player_row is not None\n",
    "\n",
    "        veracity = get_veracity(player_found, player_row, clubs_mentioned)\n",
    "        veracity_list.append(veracity)\n",
    "\n",
    "    preprocessed_data[\"veracity\"] = veracity_list\n",
    "    preprocessed_data = clean_data(preprocessed_data)\n",
    "    create_output_csv(preprocessed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc83b9e5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    preprocessed_data = utils.pandas_load_csv((\"preprocessed_data.csv\"))\n",
    "    verified_data = utils.pandas_load_csv((\"transfermarkt_data.csv\"))\n",
    "\n",
    "    wrangle_data(preprocessed_data, verified_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a05d2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
