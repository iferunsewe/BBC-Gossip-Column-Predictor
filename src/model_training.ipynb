{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f963e7ca",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "import utils\n",
    "from sklearn.impute import SimpleImputer\n",
    "from visualization_and_analysis import create_matplotlib_table, plot_confusion_matrix\n",
    "import os\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b1eb0a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Get X (features) and y (target)\n",
    "def get_X_y(data):\n",
    "    X = data.drop(['veracity', 'nationality', 'position', 'source'], axis=1)\n",
    "    y = data['veracity']\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb39767d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Impute missing values using mean imputation\n",
    "def impute_missing_values(X):\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_imputed = imputer.fit_transform(X)\n",
    "    X_imputed = pd.DataFrame(X_imputed, columns=X.columns)\n",
    "    return X_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b792f9b4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def apply_ros(X_train, y_train):\n",
    "    print(\"\\nApplying Random Over Sampling...\")\n",
    "    print(f\"Before applying ROS, the number of samples in the minority class: {y_train.value_counts()[0]}\")\n",
    "    print(f\"Before applying ROS, the number of samples in the majority class: {y_train.value_counts()[1]}\")\n",
    "\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "    print(f\"After applying ROS, the number of samples in the minority class: {y_train_resampled.value_counts()[0]}\")\n",
    "    print(f\"After applying ROS, the number of samples in the majority class: {y_train_resampled.value_counts()[1]}\")\n",
    "\n",
    "    return X_train_resampled, y_train_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f95ff1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def split_data(data, oversample=False):\n",
    "    X, y = get_X_y(data)\n",
    "    X_imputed = impute_missing_values(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.4, random_state=42)\n",
    "\n",
    "    if oversample:\n",
    "        X_train_resampled, y_train_resampled = apply_ros(X_train, y_train)\n",
    "        return X_train_resampled, X_test, y_train_resampled, y_test\n",
    "    else:\n",
    "        return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0002818b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model, X_train, X_test, y_train, y_test, cv):\n",
    "    # Train and evaluate the model on the test set\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    # Perform k-fold cross-validation and compute mean accuracy\n",
    "    cv_accuracy = np.mean(cross_val_score(model, X_train, y_train, cv=cv, scoring='accuracy'))\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    # Add cross-validated accuracy to the report dictionary\n",
    "    report['cross_validated_accuracy'] = cv_accuracy\n",
    "\n",
    "    return accuracy, cv_accuracy, report, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70027df9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def top_5_feature_importances(model, X_train):\n",
    "    total_features = len(X_train.columns)\n",
    "    feature_importances = sorted(zip(X_train.columns, model.feature_importances_), key=lambda x: x[1], reverse=True)\n",
    "    top_5_features = feature_importances[:5]\n",
    "\n",
    "    return total_features, top_5_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13349a2b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def convert_top_5_feature_importances_to_df(top_5_features):\n",
    "    return pd.DataFrame(top_5_features, columns=['Feature', 'Importance']).set_index('Feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cc844f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def print_top_5_feature_importances(model_name, model, X_train):\n",
    "    total_features, top_5_features = top_5_feature_importances(model, X_train)\n",
    "    print(f\"\\n{model_name} top 5 features out of {total_features} features:\")\n",
    "    for feature, importance in top_5_features:\n",
    "        print(f\"{feature}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8879e0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def convert_model_report_to_df(report):\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    report_df = report_df.drop(columns=['support'])\n",
    "    report_df = report_df.drop(['macro avg', 'weighted avg'])\n",
    "    return report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4876606e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def print_model_results(model_name, accuracy, cv_accuracy, report_df):\n",
    "    print(f\"\\n{model_name} cross-validated accuracy: {cv_accuracy}\")\n",
    "    print(f\"{model_name} accuracy: {accuracy:.4f}\")\n",
    "    print(\"Classification report table:\")\n",
    "    print(report_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44b084a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def print_confusion_matrix(model_name, y_test, y_pred):\n",
    "    print(f\"{model_name} confusion matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0682d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model(models, X_train, X_test, y_train, y_test, cv):\n",
    "    best_model = None\n",
    "    best_model_name = None\n",
    "    best_accuracy = 0\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\n{model_name} model:\")\n",
    "        accuracy, cv_accuracy, report, _ = train_and_evaluate_model(model, X_train, X_test, y_train, y_test, cv)\n",
    "        show_model_report_results(model_name, accuracy, cv_accuracy, report)\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_model = model\n",
    "            best_model_name = model_name\n",
    "            best_accuracy = accuracy\n",
    "\n",
    "    print(f\"\\n===================== Best model: {best_model_name} =====================\")\n",
    "\n",
    "    return best_model, best_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3d87b8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def show_model_report_results(model_name, accuracy, cv_accuracy, report, save_path=None):\n",
    "    report_df = convert_model_report_to_df(report).round(4)\n",
    "    print_model_results(model_name, accuracy, cv_accuracy, report_df)\n",
    "    if not save_path:\n",
    "        save_path = os.path.join('results', f'{model_name.lower()}_classification_report.png')\n",
    "\n",
    "    create_matplotlib_table(report_df, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba3e273",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def show_feature_importance_results(model_name, model, X_train, save_path=None):\n",
    "    print_top_5_feature_importances(model_name, model, X_train)\n",
    "    top_5_features = top_5_feature_importances(model, X_train)[1]\n",
    "    top_5_importances_df = convert_top_5_feature_importances_to_df(top_5_features).round(4)\n",
    "    if not save_path:\n",
    "        save_path = os.path.join('results', f'{model_name.lower()}_top_5_features.png')\n",
    "\n",
    "    create_matplotlib_table(top_5_importances_df, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0770049",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def show_confusion_matrix_results(model_name, y_test, y_pred, save_path=None):\n",
    "    print_confusion_matrix(model_name, y_test, y_pred)\n",
    "    if not save_path:\n",
    "        save_path = os.path.join('results', f'{model_name.lower()}_confusion_matrix.png')\n",
    "    plot_confusion_matrix(model_name, y_test, y_pred, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c20f77",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_models(data):\n",
    "    X_train, X_test, y_train, y_test = split_data(data)\n",
    "\n",
    "    models = {\n",
    "        'Random Forest': RandomForestClassifier(random_state=42),\n",
    "        'AdaBoost': AdaBoostClassifier(random_state=42),\n",
    "        'XGBoost': XGBClassifier(random_state=42, eval_metric='mlogloss')\n",
    "    }\n",
    "\n",
    "    # Using StratifiedKFold to maintain class distribution across folds\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    best_model, best_model_name = find_best_model(models, X_train, X_test, y_train, y_test, cv)\n",
    "\n",
    "    X_train_resampled, X_test, y_train_resampled, y_test = split_data(data, oversample=True)\n",
    "    best_accuracy, best_cv_accuracy, best_report, best_y_pred = train_and_evaluate_model(best_model, X_train_resampled, X_test, y_train_resampled, y_test, cv)\n",
    "\n",
    "    best_report_save_path = os.path.join('results', f'{best_model_name.lower()}_classification_report_oversampled_data.png')\n",
    "    show_model_report_results(best_model_name, best_accuracy, best_cv_accuracy, best_report, save_path=best_report_save_path)\n",
    "\n",
    "    best_feature_importance_save_path = os.path.join('results', f'{best_model_name.lower()}_top_5_features_oversampled_data.png')\n",
    "    show_feature_importance_results(best_model_name, best_model, X_train_resampled, save_path=best_feature_importance_save_path)\n",
    "\n",
    "    best_confusion_matrix_save_path = os.path.join('results', f'{best_model_name.lower()}_confusion_matrix_oversampled_data.png')\n",
    "    show_confusion_matrix_results(best_model_name, y_test, best_y_pred, save_path=best_confusion_matrix_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457b3a44",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    output_data = utils.pandas_load_csv(\"output_data.csv\")\n",
    "    \n",
    "    train_and_evaluate_models(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20d1464",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
